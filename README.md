# Hands on RL

> [!NOTE]
> 
> To solve the questions in the Weeks (If you are interested ðŸ˜Š), check out the Questions folder in the Weeks.
> Check out the [**Course Info**](CourseInfo.md) file for more details!
> 
> Note: The books that have copyrights aren't being uploaded here.
> The books in the Resources/Books/ directory are downloaded from the sources listed in the
> 'Books and Resources' section.
> 
> If you want to learn from this repository(â¤ï¸), follow the README files to stay organized and on track.
> ## License 
> This work is licensed under the
> [**Creative Commons Attribution-ShareAlike 4.0 International License**](https://creativecommons.org/licenses/by-sa/4.0/legalcode).
> 
> Refer [**this**](https://github.com/rennaMAhcuS/Hands-on-RL-Source) for more info!

## [Books and Resources](Resources/Books)

- [**Grokking RL**](https://www.google.co.in/books/edition/Grokking_Deep_Reinforcement_Learning/-7YCEAAAQBAJ):
  I didn't find an official resource ðŸ˜¢...
  
  <!-- The book is available [**here**](Resources/Books/Grokking_RL.pdf). -->

- [**Sutton and Barto**](https://www.google.co.in/books/edition/Reinforcement_Learning_second_edition/5s-MEAAAQBAJ):
  This book can be downloaded from:
  
  - [**Carnegie Mellon University's website**](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf)
  - [**Stanford University's website**](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)
  - [**Direct PDF**](Resources/Books/Sutton_and_Barto.pdf)

- [**Thompson Sampling**](https://www.google.co.in/books/edition/A_Tutorial_on_Thompson_Sampling/nXx6uQEACAAJ):
  This resource can be obtained from:
  
  - [**Stanford University's website**](https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf)
  - [**Direct PDF**](Resources/Books/TS_Tutorial.pdf)

## Repository Structure

<!-- The one that is visible in GitHub Remote. -->

```text
.
â”œâ”€â”€ Resources/
â”‚   â””â”€â”€ Books/
â”œâ”€â”€ Week1/
â”‚   â”œâ”€â”€ Assignment/
â”‚   â”œâ”€â”€ {Solved Files}  # Files related to solved questions
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ Week2/
â”‚   â”œâ”€â”€ Assignment/
â”‚   â”œâ”€â”€ {Solved Files}  # Files related to solved questions
â”‚   â””â”€â”€ README.md
.
. (Continue similarly for other weeks)
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CourseInfo.md
â””â”€â”€ README.md
```

## [Week 1](Week1)

This week covers the basic topics of **`python`** required for **Machine Learning** and **Reinforcement Learning**.
The basics of **Reinforcement Learning** are also covered in the books **Grokking RL** and **Sutton and Barto**.

## [Week 2](Week2)

This week covers the basics of **Reinforcement Learning**, mainly covered from **Grokking RL**.
It also has an assignment to cover the basics of writing a game in **`python`** using the **`pygame`** module.

## [Week 3](Week3)

This week covers the algorithms to deal with **Prediction and Control problems**.

## [Week 4](Week4)

This week covers the implementation of the Multi-armed bandit problem implemented in **`python`**.

## [Week 5](Week5)

This week covers **Temporal Difference Learning**, **Q Learning** and **Eligibility Traces** along with a simple game
and using **Q-learning** to **"solve"** the environment.

## [Week 6](Week6)

We have reached the ending!
We will be implementing [**this paper**](Week6/thesis.pdf) to create a Chess Engine based on Deep RL.

---

# Happy Learning ðŸ¥°!

---

> [!TIP]
> 
> There were some dead weeks also in between in my SoC.
> Considering those also would make this an ~8-Week course.
> I have removed all the inactive weeks from this repository to streamline it for convenient learning.

